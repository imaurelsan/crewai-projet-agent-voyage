#!/usr/bin/env python
"""Agent Weather Specialist avec outils pour r√©cup√©rer la m√©t√©o r√©elle"""

import os
import requests
from dotenv import load_dotenv
from langchain_ollama import OllamaLLM
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.tools import tool

load_dotenv()

# Configuration
OLLAMA_MODEL = os.getenv("OLLAMA_MODEL", "llama3.2:3b")
OLLAMA_BASE_URL = os.getenv("OLLAMA_BASE_URL", "http://localhost:11434")

# Initialiser le LLM
llm = OllamaLLM(model=OLLAMA_MODEL, base_url=OLLAMA_BASE_URL, temperature=0.7)

print(f"‚úÖ Weather Specialist Agent - Mod√®le: {OLLAMA_MODEL}\n")

# ============= OUTILS M√âT√âO =============

@tool
def get_weather(city: str) -> str:
    """
    R√©cup√®re la m√©t√©o actuelle pour une ville.
    
    Args:
        city: Le nom de la ville (ex: Paris, Tokyo, New York)
    
    Returns:
        Les informations m√©t√©o actuelles
    """
    try:
        # Utiliser wttr.in - API m√©t√©o gratuite
        url = f"https://wttr.in/{city}?format=j1"
        response = requests.get(url, timeout=15)
        
        if response.status_code == 200:
            data = response.json()
            current = data['current_condition'][0]
            
            temp_c = current['temp_C']
            feels_like = current['FeelsLikeC']
            weather_desc = current['weatherDesc'][0]['value']
            humidity = current['humidity']
            wind_speed = current['windspeedKmph']
            
            result = f"""M√©t√©o actuelle √† {city}:
üå°Ô∏è Temp√©rature: {temp_c}¬∞C (ressenti {feels_like}¬∞C)
‚òÅÔ∏è Conditions: {weather_desc}
üíß Humidit√©: {humidity}%
üí® Vent: {wind_speed} km/h"""
            
            return result
        else:
            return f"‚ùå Impossible de r√©cup√©rer la m√©t√©o pour {city}"
    except Exception as e:
        return f"‚ùå Erreur: {str(e)}"

@tool
def compare_weather(city1: str, city2: str) -> str:
    """
    Compare la m√©t√©o actuelle entre deux villes.
    
    Args:
        city1: Premi√®re ville
        city2: Deuxi√®me ville
    
    Returns:
        Comparaison des conditions m√©t√©o
    """
    try:
        # R√©cup√©rer la m√©t√©o des deux villes
        url1 = f"https://wttr.in/{city1}?format=j1"
        url2 = f"https://wttr.in/{city2}?format=j1"
        
        response1 = requests.get(url1, timeout=15)
        response2 = requests.get(url2, timeout=15)
        
        if response1.status_code == 200 and response2.status_code == 200:
            data1 = response1.json()['current_condition'][0]
            data2 = response2.json()['current_condition'][0]
            
            temp1 = int(data1['temp_C'])
            temp2 = int(data2['temp_C'])
            
            result = f"""Comparaison m√©t√©o entre {city1} et {city2}:

üìç {city1}:
   üå°Ô∏è {temp1}¬∞C ({data1['weatherDesc'][0]['value']})
   üíß Humidit√©: {data1['humidity']}%
   üí® Vent: {data1['windspeedKmph']} km/h

üìç {city2}:
   üå°Ô∏è {temp2}¬∞C ({data2['weatherDesc'][0]['value']})
   üíß Humidit√©: {data2['humidity']}%
   üí® Vent: {data2['windspeedKmph']} km/h

üìä Diff√©rence de temp√©rature: {abs(temp1 - temp2)}¬∞C
{'üî• ' + city1 + ' est plus chaud' if temp1 > temp2 else '‚ùÑÔ∏è ' + city2 + ' est plus chaud' if temp2 > temp1 else '‚öñÔ∏è Temp√©rature identique'}"""
            
            return result
        else:
            return f"‚ùå Impossible de comparer les m√©t√©os"
    except Exception as e:
        return f"‚ùå Erreur: {str(e)}"

# Liste des outils disponibles
tools = [get_weather, compare_weather]

# ============= AGENT M√âT√âO =============

# Note: LangChain avec Ollama ne supporte pas encore nativement le function calling
# On va donc cr√©er un syst√®me simple o√π l'agent d√©cide quelle fonction appeler

def weather_agent(question: str):
    """
    Agent m√©t√©o qui peut utiliser des outils
    """
    print(f"{'='*70}")
    print(f"‚òÅÔ∏è WEATHER SPECIALIST AGENT")
    print(f"{'='*70}\n")
    print(f"‚ùì Question: {question}\n")
    
    # Analyser la question pour d√©terminer quelle fonction utiliser
    question_lower = question.lower()
    
    # D√©tecter si c'est une comparaison
    if any(word in question_lower for word in ['compare', 'comparer', 'diff√©rence', 'vs', 'versus', 'entre']):
        print("üîç D√©tection: Comparaison de m√©t√©o demand√©e\n")
        
        # Extraire les villes (simple parsing)
        words = question.replace(',', ' ').replace('et', ' ').split()
        cities = []
        for i, word in enumerate(words):
            if word.lower() in ['entre', 'et', 'vs', 'versus', 'compare', 'comparer']:
                continue
            if len(word) > 2 and word[0].isupper():
                cities.append(word)
        
        if len(cities) >= 2:
            print(f"üåç Villes d√©tect√©es: {cities[0]} et {cities[1]}\n")
            print("ü§ñ L'agent appelle l'outil compare_weather...\n")
            result = compare_weather.invoke({"city1": cities[0], "city2": cities[1]})
            
            print(f"{'='*70}")
            print("‚úÖ R√âSULTAT")
            print(f"{'='*70}\n")
            print(result)
            
            # Demander √† l'agent d'interpr√©ter
            print(f"\n{'='*70}")
            print("ü§ñ ANALYSE DE L'AGENT")
            print(f"{'='*70}\n")
            
            analysis_prompt = f"""Bas√© sur ces donn√©es m√©t√©o:

{result}

Donne une recommandation de voyage: quelle ville est plus agr√©able √† visiter en ce moment et pourquoi? 
Sois concis et pratique."""
            
            analysis = llm.invoke(analysis_prompt)
            print(analysis)
            
        else:
            print("‚ùå Impossible de d√©tecter deux villes pour la comparaison")
    
    # Sinon, c'est une requ√™te simple de m√©t√©o
    else:
        print("üîç D√©tection: Requ√™te m√©t√©o simple\n")
        
        # Extraire la ville - chercher les mots-cl√©s
        question_clean = question.replace('?', '').replace(',', '')
        words = question_clean.split()
        
        # Liste de mots √† ignorer
        skip_words = ['quel', 'quelle', 'temps', 'fait', 'il', 'la', 'le', 'm√©t√©o', '√†', 'dans', 'de', 'du']
        
        city = None
        for word in words:
            if len(word) > 2 and word[0].isupper() and word.lower() not in skip_words:
                city = word
                break
        
        if city:
            print(f"üåç Ville d√©tect√©e: {city}\n")
            print("ü§ñ L'agent appelle l'outil get_weather...\n")
            result = get_weather.invoke({"city": city})
            
            print(f"{'='*70}")
            print("‚úÖ R√âSULTAT")
            print(f"{'='*70}\n")
            print(result)
            
            # Demander √† l'agent de donner des conseils
            print(f"\n{'='*70}")
            print("ü§ñ CONSEILS DE L'AGENT")
            print(f"{'='*70}\n")
            
            advice_prompt = f"""Bas√© sur cette m√©t√©o:

{result}

Donne 2-3 conseils pratiques pour un voyageur visitant cette ville aujourd'hui.
Sois concis et utile."""
            
            advice = llm.invoke(advice_prompt)
            print(advice)
        else:
            print("‚ùå Impossible de d√©tecter une ville dans la question")

if __name__ == "__main__":
    print("‚òÅÔ∏è WEATHER SPECIALIST AGENT\n")
    print("Cet agent peut:")
    print("  1Ô∏è‚É£  R√©cup√©rer la m√©t√©o actuelle d'une ville")
    print("  2Ô∏è‚É£  Comparer la m√©t√©o entre deux villes\n")
    
    print("Exemples de questions:")
    print('  - "Quel temps fait-il √† Paris ?"')
    print('  - "Compare la m√©t√©o entre Tokyo et Paris"')
    print('  - "Quelle est la diff√©rence de temp√©rature entre Londres et Madrid ?"\n')
    
    question = input("Votre question (ou Entr√©e pour tester): ").strip()
    
    if not question:
        # Test par d√©faut
        print("\nüß™ Test 1: M√©t√©o simple\n")
        weather_agent("Quel temps fait-il √† Paris ?")
        
        print("\n" + "="*70)
        print("\nüß™ Test 2: Comparaison\n")
        weather_agent("Compare la m√©t√©o entre Tokyo et Paris")
    else:
        weather_agent(question)
