# üìò Guide de D√©veloppement - Pour D√©butants

Ce guide vous explique **√©tape par √©tape** comment fonctionne le projet et comment le d√©velopper, m√™me si vous d√©butez en programmation.

## üìö Table des mati√®res

1. [Pr√©requis et installation](#1-pr√©requis-et-installation)
2. [Concepts de base](#2-concepts-de-base)
3. [Architecture du projet](#3-architecture-du-projet)
4. [Cr√©er votre premier agent](#4-cr√©er-votre-premier-agent)
5. [Ajouter des outils √† un agent](#5-ajouter-des-outils-√†-un-agent)
6. [Cr√©er un Crew complet](#6-cr√©er-un-crew-complet)
7. [Personnaliser la configuration](#7-personnaliser-la-configuration)
8. [D√©boguer votre code](#8-d√©boguer-votre-code)
9. [Aller plus loin](#9-aller-plus-loin)

---

## 1. Pr√©requis et installation

### üîß Ce dont vous avez besoin

1. **Python 3.13** - Le langage de programmation
2. **Ollama** - Le serveur qui fait tourner l'intelligence artificielle localement
3. **Un √©diteur de code** - VS Code recommand√© (gratuit)

### üì• Installation pas √† pas

#### √âtape 1 : Installer Python 3.13

```powershell
# T√©l√©charger depuis https://www.python.org/downloads/
# Cocher "Add Python to PATH" lors de l'installation
# V√©rifier l'installation :
py -3.13 --version
# Devrait afficher : Python 3.13.x
```

#### √âtape 2 : Installer Ollama

```powershell
# T√©l√©charger depuis https://ollama.ai/download
# Installer le fichier t√©l√©charg√©
# V√©rifier l'installation :
ollama --version
# Devrait afficher : ollama version 0.x.x
```

#### √âtape 3 : T√©l√©charger le mod√®le IA

```powershell
# T√©l√©charger le mod√®le Llama 3.2 (2GB)
ollama pull llama3.2:3b

# V√©rifier qu'il est bien install√©
ollama list
# Devrait afficher : llama3.2:3b
```

#### √âtape 4 : Cr√©er l'environnement virtuel

```powershell
# Se placer dans le dossier du projet
cd C:\chemin\vers\crewai-projet-agent-voyage

# Cr√©er un environnement virtuel (venv)
py -3.13 -m venv venv

# Activer l'environnement
.\venv\Scripts\Activate.ps1

# Votre terminal devrait maintenant afficher (venv) au d√©but
```

**üí° C'est quoi un environnement virtuel ?**
C'est comme une bulle isol√©e pour votre projet. Toutes les biblioth√®ques install√©es ici ne pollueront pas le reste de votre syst√®me.

#### √âtape 5 : Installer les d√©pendances

```powershell
# Installer toutes les biblioth√®ques n√©cessaires
pip install -r requirements.txt

# Cela installe :
# - langchain : framework pour cr√©er des agents
# - langchain-ollama : pour connecter Ollama
# - requests : pour faire des requ√™tes HTTP (m√©t√©o)
# - python-dotenv : pour g√©rer les variables d'environnement
# - pyyaml : pour lire les fichiers de configuration
```

#### √âtape 6 : Configurer les variables d'environnement

Cr√©ez un fichier `.env` √† la racine du projet :

```env
OLLAMA_MODEL=llama3.2:3b
OLLAMA_BASE_URL=http://localhost:11434
```

**üí° C'est quoi un fichier .env ?**
C'est un fichier qui contient des param√®tres de configuration. Comme √ßa, on ne met pas les param√®tres directement dans le code.

---

## 2. Concepts de base

### ü§ñ Qu'est-ce qu'un Agent ?

Un **agent** est comme un employ√© virtuel sp√©cialis√©. Il a :
- **Un r√¥le** : par exemple "Expert en voyages"
- **Un objectif** : ce qu'il doit accomplir
- **Une histoire** (backstory) : son exp√©rience
- **Des outils** (optionnel) : des fonctions qu'il peut utiliser

**Exemple concret :**
```python
agent_meteo = Agent(
    role="Sp√©cialiste M√©t√©o",
    goal="Fournir des infos m√©t√©o pr√©cises",
    backstory="Vous √™tes un m√©t√©orologue avec 10 ans d'exp√©rience",
    tools=[get_weather]  # Il peut utiliser cet outil
)
```

### üìã Qu'est-ce qu'une Task (t√¢che) ?

Une **task** est une mission donn√©e √† un agent.

```python
tache_meteo = Task(
    description="Analyser la m√©t√©o √† Paris",
    expected_output="Un rapport m√©t√©o d√©taill√©",
    agent=agent_meteo  # Quel agent fait cette t√¢che
)
```

### üë• Qu'est-ce qu'un Crew ?

Un **crew** est une √©quipe d'agents qui travaillent ensemble.

```python
crew = Crew(
    agents=[agent1, agent2, agent3],
    tasks=[task1, task2, task3],
    process=Process.sequential  # Les t√¢ches se font dans l'ordre
)
```

### üîÑ Processus s√©quentiel

Les t√¢ches s'ex√©cutent **dans l'ordre** :
```
Agent 1 ‚Üí Agent 2 ‚Üí Agent 3 ‚Üí R√©sultat final
```

Chaque agent re√ßoit les r√©sultats des agents pr√©c√©dents.

---

## 3. Architecture du projet

### üìÇ Structure des dossiers

```
crewai-projet-agent-voyage/
‚îÇ
‚îú‚îÄ‚îÄ config/                    # üìÅ Configuration
‚îÇ   ‚îú‚îÄ‚îÄ agents.yaml           # D√©finition des agents
‚îÇ   ‚îî‚îÄ‚îÄ tasks.yaml            # D√©finition des t√¢ches
‚îÇ
‚îú‚îÄ‚îÄ src/                       # üìÅ Code source
‚îÇ   ‚îú‚îÄ‚îÄ crewai_simulator.py   # Le "moteur" qui fait tourner les agents
‚îÇ   ‚îî‚îÄ‚îÄ crew_voyage.py        # Votre crew principal
‚îÇ
‚îú‚îÄ‚îÄ agent_meteo.py            # Exemple d'agent simple
‚îú‚îÄ‚îÄ exemple_simple.py         # Exemple minimal
‚îú‚îÄ‚îÄ .env                       # Variables de configuration
‚îî‚îÄ‚îÄ requirements.txt           # Liste des biblioth√®ques
```

### üéØ Fichiers importants

| Fichier | R√¥le | Quand le modifier |
|---------|------|-------------------|
| `config/agents.yaml` | D√©finit les agents (r√¥le, objectif) | Pour changer la personnalit√© d'un agent |
| `config/tasks.yaml` | D√©finit les t√¢ches | Pour changer ce que font les agents |
| `src/crew_voyage.py` | Crew principal | Pour ajouter/retirer des agents |
| `.env` | Configuration | Pour changer le mod√®le IA |

---

## 4. Cr√©er votre premier agent

### √âtape 1 : Agent simple (sans framework)

Cr√©ez un fichier `mon_premier_agent.py` :

```python
# 1. Importer les biblioth√®ques
from langchain_ollama import OllamaLLM
from langchain_core.prompts import ChatPromptTemplate
from dotenv import load_dotenv
import os

# 2. Charger les variables d'environnement
load_dotenv()

# 3. Cr√©er le mod√®le IA
llm = OllamaLLM(
    model=os.getenv("OLLAMA_MODEL", "llama3.2:3b"),
    base_url=os.getenv("OLLAMA_BASE_URL", "http://localhost:11434"),
    temperature=0.7  # Plus c'est √©lev√©, plus c'est cr√©atif
)

# 4. Cr√©er le prompt (instructions pour l'IA)
prompt = ChatPromptTemplate.from_template("""
Tu es un guide touristique expert.
Recommande 3 activit√©s √† faire √† {ville}.
Sois concis et enthousiaste.
""")

# 5. Cr√©er la cha√Æne (prompt + IA)
chain = prompt | llm

# 6. Utiliser l'agent
if __name__ == "__main__":
    ville = input("Quelle ville voulez-vous visiter ? ")
    resultat = chain.invoke({"ville": ville})
    print("\n" + "="*50)
    print(resultat)
    print("="*50)
```

**Tester :**
```powershell
python mon_premier_agent.py
```

### √âtape 2 : Comprendre le code

```python
# ChatPromptTemplate = Le "script" que va suivre l'IA
prompt = ChatPromptTemplate.from_template("...")

# | = Pipe, √ßa connecte le prompt √† l'IA
chain = prompt | llm

# invoke = Lancer l'agent avec des param√®tres
resultat = chain.invoke({"ville": "Paris"})
```

**üí° Astuce :** La `temperature` contr√¥le la cr√©ativit√© :
- `0.0` = R√©ponses identiques et pr√©visibles
- `1.0` = R√©ponses tr√®s cr√©atives et vari√©es

---

## 5. Ajouter des outils √† un agent

### Qu'est-ce qu'un outil ?

Un **outil** est une fonction Python que l'agent peut appeler. Exemple : r√©cup√©rer la m√©t√©o, chercher sur Google, lire un fichier.

### Cr√©er un outil simple

Cr√©ez `agent_avec_outil.py` :

```python
from langchain_core.tools import tool
from langchain_ollama import OllamaLLM
import requests

# 1. Cr√©er l'outil avec le d√©corateur @tool
@tool
def get_weather(city: str) -> str:
    """R√©cup√®re la m√©t√©o actuelle pour une ville"""
    try:
        url = f"https://wttr.in/{city}?format=j1"
        response = requests.get(url, timeout=15)
        
        if response.status_code == 200:
            data = response.json()
            current = data['current_condition'][0]
            
            return f"""M√©t√©o √† {city}:
üå°Ô∏è {current['temp_C']}¬∞C
‚òÅÔ∏è {current['weatherDesc'][0]['value']}
üíß Humidit√©: {current['humidity']}%"""
        else:
            return f"M√©t√©o non disponible pour {city}"
    except Exception as e:
        return f"Erreur: {str(e)}"

# 2. Utiliser l'outil
if __name__ == "__main__":
    city = input("Quelle ville ? ")
    
    # Appeler directement l'outil
    result = get_weather.invoke({"city": city})
    print(result)
```

**üí° Le d√©corateur `@tool` :**
- Transforme une fonction normale en "outil" pour les agents
- L'IA pourra d√©cider quand utiliser cet outil
- Le docstring (""") est important : il explique √† l'IA ce que fait l'outil

---

## 6. Cr√©er un Crew complet

### Architecture CrewAI

Notre projet utilise des **d√©corateurs** pour organiser le code comme dans CrewAI :

```python
@CrewBase      # Marque la classe comme un Crew
class MonCrew():
    
    @agent     # Marque une m√©thode comme agent
    def mon_agent(self):
        return Agent(...)
    
    @task      # Marque une m√©thode comme t√¢che
    def ma_tache(self):
        return Task(...)
    
    @crew      # Marque une m√©thode comme crew
    def crew(self):
        return Crew(...)
```

### Cr√©er un mini-crew

Cr√©ez `mini_crew.py` :

```python
import sys
import os
sys.path.insert(0, os.path.dirname(__file__))

from src.crewai_simulator import Agent, Task, Crew, Process, CrewBase, agent, task, crew, LLM

@CrewBase
class MiniCrew():
    """Mon premier crew"""
    
    def __init__(self):
        self.llm = LLM(model="llama3.2:3b")
    
    @agent
    def guide(self) -> Agent:
        """Agent guide touristique"""
        return Agent(
            role="Guide Touristique",
            goal="Recommander les meilleures attractions",
            backstory="Vous √™tes un guide avec 10 ans d'exp√©rience",
            llm=self.llm
        )
    
    @agent
    def chef(self) -> Agent:
        """Agent expert culinaire"""
        return Agent(
            role="Chef Cuisinier",
            goal="Recommander les meilleurs restaurants",
            backstory="Vous √™tes un chef √©toil√© qui conna√Æt tous les restaurants",
            llm=self.llm
        )
    
    @task
    def attractions_task(self) -> Task:
        """Trouver les attractions"""
        return Task(
            description="Liste 3 attractions principales √† {ville}",
            expected_output="Une liste de 3 attractions avec descriptions",
            agent=self.guide()
        )
    
    @task
    def restaurants_task(self) -> Task:
        """Trouver les restaurants"""
        return Task(
            description="Recommande 3 restaurants √† {ville}",
            expected_output="Une liste de 3 restaurants avec sp√©cialit√©s",
            agent=self.chef()
        )
    
    @crew
    def crew(self) -> Crew:
        """Cr√©er l'√©quipe"""
        return Crew(
            agents=[self.guide(), self.chef()],
            tasks=[self.attractions_task(), self.restaurants_task()],
            process=Process.sequential,
            verbose=True
        )

# Utilisation
if __name__ == "__main__":
    ville = input("Quelle ville ? ")
    
    mon_crew = MiniCrew()
    resultat = mon_crew.crew().kickoff(inputs={'ville': ville})
    
    print("\n" + "="*70)
    print("R√âSULTAT FINAL")
    print("="*70)
    print(resultat)
```

**Tester :**
```powershell
python mini_crew.py
```

---

## 7. Personnaliser la configuration

### Modifier les agents (agents.yaml)

Ouvrez `config/agents.yaml` :

```yaml
mon_agent:
  role: "Expert en Quelque Chose"
  goal: "Atteindre cet objectif"
  backstory: |
    Vous √™tes un expert avec X ann√©es d'exp√©rience.
    Vous √™tes passionn√© par votre domaine.
```

**Conseils :**
- Le `role` doit √™tre court et clair
- Le `goal` doit √™tre sp√©cifique
- Le `backstory` donne de la personnalit√©

### Modifier les t√¢ches (tasks.yaml)

Ouvrez `config/tasks.yaml` :

```yaml
ma_tache:
  description: |
    Fais ceci et cela pour {variable}.
    Inclue:
    - Point 1
    - Point 2
  expected_output: |
    Un rapport d√©taill√© avec ces sections:
    - Section 1
    - Section 2
```

**Conseils :**
- Utilisez `{variable}` pour les param√®tres dynamiques
- Soyez pr√©cis sur ce que vous attendez
- Le `expected_output` guide l'IA sur le format

---

## 8. D√©boguer votre code

### Erreurs courantes

#### Erreur 1 : "ModuleNotFoundError"

```python
ModuleNotFoundError: No module named 'langchain'
```

**Solution :**
```powershell
# V√©rifier que le venv est activ√© (doit afficher (venv))
.\venv\Scripts\Activate.ps1

# R√©installer les d√©pendances
pip install -r requirements.txt
```

#### Erreur 2 : "Ollama connection refused"

```python
requests.exceptions.ConnectionError: ... connection refused
```

**Solution :**
```powershell
# V√©rifier qu'Ollama tourne
ollama list

# Si pas de r√©ponse, relancer Ollama
# Sous Windows: chercher "Ollama" dans le menu d√©marrer
```

#### Erreur 3 : R√©ponse vide ou incoh√©rente

**Causes possibles :**
- Le prompt n'est pas assez clair
- Le `backstory` ne correspond pas √† la t√¢che
- La `temperature` est trop √©lev√©e

**Solution :**
```python
# Rendre le prompt plus pr√©cis
description = """
Analyse PR√âCIS√âMENT la m√©t√©o √† {ville}.
Format attendu:
1. Temp√©rature actuelle
2. Conditions (soleil, pluie, etc.)
3. Recommandation vestimentaire
"""

# Baisser la temperature
llm = OllamaLLM(model="llama3.2:3b", temperature=0.3)
```

### Mode debug

Ajoutez des prints pour voir ce qui se passe :

```python
print(f"üîç Prompt envoy√©: {prompt_text}")
print(f"ü§ñ R√©ponse IA: {result}")
```

---

## 9. Aller plus loin

### Id√©es de nouveaux agents

1. **Agent de Transport**
   - Trouve les meilleurs moyens de transport
   - Estime les temps de trajet
   - Compare les prix

2. **Agent d'H√©bergement**
   - Recommande des h√¥tels/Airbnb
   - Compare les prix
   - V√©rifie les avis

3. **Agent de S√©curit√©**
   - Informe sur les pr√©cautions √† prendre
   - Zones √† √©viter
   - Vaccins n√©cessaires

### Ajouter un nouvel outil

Exemple : Recherche Google

```python
@tool
def search_google(query: str) -> str:
    """Recherche sur Google"""
    # N√©cessite une cl√© API Google
    # Voir: https://developers.google.com/custom-search/
    pass
```

### Modifier le processus

Au lieu de `Process.sequential`, vous pourriez :
- Cr√©er un processus parall√®le (tous les agents en m√™me temps)
- Cr√©er un processus conditionnel (si X alors Y)

**Exemple conceptuel :**
```python
# Aujourd'hui: s√©quentiel
Agent1 ‚Üí Agent2 ‚Üí Agent3

# Parall√®le (√† impl√©menter)
Agent1 ‚Üò
        ‚Üí Agent3
Agent2 ‚Üó

# Conditionnel (√† impl√©menter)
Agent1 ‚Üí Si budget > 1000‚Ç¨ ‚Üí AgentLuxe
      ‚Üí Sinon ‚Üí AgentEconomique
```

### Exporter vers une API

Pour cr√©er une API web, utilisez FastAPI :

```python
from fastapi import FastAPI

app = FastAPI()

@app.post("/planifier-voyage")
def planifier(destination: str):
    crew = TravelCrew()
    result = crew.crew().kickoff(inputs={'destination': destination})
    return {"plan": result}

# Lancer avec: uvicorn api.main:app --reload
```

---

## üìö Ressources suppl√©mentaires

### Documentation officielle

- [LangChain](https://python.langchain.com/docs/get_started/introduction)
- [Ollama](https://github.com/ollama/ollama)
- [CrewAI](https://docs.crewai.com/)

### Tutoriels recommand√©s

- [Python pour d√©butants](https://www.python.org/about/gettingstarted/)
- [YAML expliqu√©](https://yaml.org/spec/1.2/spec.html)
- [Comprendre les LLMs](https://en.wikipedia.org/wiki/Large_language_model)

### Communaut√©s

- Discord LangChain
- Forum CrewAI
- Stack Overflow (tag: langchain)

---

## üéì Exercices pratiques

### Exercice 1 : Modifier un agent

**Objectif :** Changer la personnalit√© de l'agent m√©t√©o

1. Ouvrir `config/agents.yaml`
2. Modifier le `backstory` de `weather_specialist`
3. Tester avec `python agent_meteo.py`

### Exercice 2 : Ajouter une t√¢che

**Objectif :** Cr√©er une t√¢che "activit√©s nocturnes"

1. Ouvrir `config/tasks.yaml`
2. Ajouter une nouvelle t√¢che :
```yaml
nightlife_task:
  description: "Recommande 3 activit√©s nocturnes √† {destination}"
  expected_output: "Liste de bars, clubs et spectacles"
```
3. Cr√©er l'agent et la t√¢che dans `src/crew_voyage.py`

### Exercice 3 : Cr√©er votre propre crew

**Objectif :** Crew pour planifier un anniversaire

Agents n√©cessaires :
- Agent Restaurant
- Agent Cadeaux
- Agent Animation
- Agent Coordinateur

---

## ‚ùì FAQ - Questions fr√©quentes

**Q: Pourquoi Python 3.13 sp√©cifiquement ?**
R: Les versions plus r√©centes (3.14+) ne sont pas compatibles avec certaines biblioth√®ques. 3.13 est le sweet spot.

**Q: Ollama consomme-t-il beaucoup de ressources ?**
R: Avec llama3.2:3b, comptez environ 4GB de RAM. C'est raisonnable pour un PC moderne.

**Q: Peut-on utiliser ChatGPT au lieu d'Ollama ?**
R: Oui, mais il faut une cl√© API OpenAI (payant). Modifiez le `LLM()` en cons√©quence.

**Q: Les r√©ponses sont lentes, c'est normal ?**
R: Oui, Ollama en local est plus lent que les API cloud. Soyez patient (5-30 secondes par r√©ponse).

**Q: Comment contribuer au projet ?**
R: Fork sur GitHub, faites vos modifications, puis cr√©ez une Pull Request.

---

üéâ **F√©licitations !** Vous savez maintenant cr√©er des agents intelligents et des crews complets. Bonne exploration ! üöÄ
